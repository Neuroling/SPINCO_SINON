Blcks
knitr::opts_chunk$set(echo = TRUE)
library(gridExtra)
library(dplyr)
library(plotly)
library(ggplot2)
library(nomnoml)
library(kableExtra)
# Generate sequences for experimental blocks
nNoiseLevels <- 5
nTrialsInSeq <- 60
snrpreffix <-  paste0('SNR',1:nNoiseLevels,'')
subsets <- list()
for (i  in 1:length(sets)) {
currseq <- c(sets[[i]]$Word[1:(nTrialsInSeq/2)],
sets[[i]]$pseudoword[1:(nTrialsInSeq/2)])
#Make n blocks, one for each SNR
blocks <- list()
for (ii in 1:length(currseq)) {
blocks[[ii]] <- paste(snrpreffix,currseq[ii],sep='_')[order(sample(1:5))]
}
Blcks <- as.data.frame(do.call(rbind,blocks))
Blcks <- apply(Blcks,2,sample) # shuffle the rows of each column independently
colnames(Blcks) <- paste0('version',1:dim(Blcks)[2])
subsets[[i]] <- as.data.frame(Blcks)
}
# Read data
rm(list=ls())
if( .Platform$OS.type == "windows" ){ dirinput <- 'V:/gfraga/'
} else if ( .Platform$OS.type == "unix"){ dirinput <- '/run/user/891957923/gvfs/smb-share:domain=d.uzh.ch,server=idnas12.d.uzh.ch,share=g_psyneulin_data$,user=gfraga/gfraga'
}
Merged <- openxlsx::read.xlsx(paste0(dirinput,'/Neuroling_SINON_stimuli.xlsx'),sheet = 'Merged')
Merged <- openxlsx::read.xlsx(paste0(dirinput,'/Neuroling_SINON_stimuli.xlsx'),sheet = 'Merged')
# Select only valid cases (e.g., Phono info available)
dat <- Merged[!is.na(Merged$PhoWord),]
# Outlier rejection:
#lgSubtlex
boxstats <- boxplot.stats(dat$lgSUBTLEX)
dat <- dat[dat$lgSUBTLEX > boxstats$stats[1] & dat$lgSUBTLEX < boxstats$stats[5],]
rm(boxstats)
#PTAN (neighbor metric: phonological, neighbor metric: all, neighborhood frequency: all, value: size)
boxstats <- boxplot.stats(dat$PTAN)
dat <- dat[dat$PTAN > boxstats$stats[1] & dat$PTAN < boxstats$stats[5],]
rm(boxstats)
#ned1_diff (for associated Wuggy-pseudowords)
boxstats <- boxplot.stats(dat$Ned1_Diff)
dat <- dat[dat$Ned1_Diff > boxstats$stats[1] & dat$Ned1_Diff < boxstats$stats[5],]
# Include a pseudoword variable
dat$pseudoword <- gsub('-','',dat$Match)
dat$pseudoword[ !is.na(dat$Alternative)] <- gsub('-','',dat$Alternative)[!is.na(dat$Alternative)]
# retrieve word 2 initial sounds
dat$wordInitSounds <- paste0(sapply(strsplit(dat$PhoWord,".",fixed=TRUE),"[[",1),sapply(strsplit(dat$PhoWord,".",fixed=TRUE),"[[",2))
dat$syllableCount <- as.factor(sapply(strsplit(dat$Match,'-'),length))
### Split in 'balanced' sets
#-------------------------------------
#-  Pairwise comparisons in : lgSUBTLEX, PTAN,Ned1_Diff
#-  Compare proportions (i.e., n trials) for: item length, n syllables
nTrialsInSet <- 60
nSets <- 5
if(nTrialsInSet*nSets !=nrow(dat)){
warning('Trimming dataset to match nTrialsInSet*nSets')
}
# Select files from set
dat <- dat[sample(nrow(dat)),] # first shuffle to avoid bias by alphabetic sorting
dat <- dat[1:(nSets*nTrialsInSet),] # trim
# Add info for subsetting
dat$setIdx <- as.factor(rep(1:nSets, each = nTrialsInSet))
dat$setTrial <- as.factor(rep(1:nTrialsInSet,nSets))
# Compare the sets pairwise on several key variables. If finding significant differences in any of them: shuffle data,  reasign set and trials indices and compare again
vars2test <- c('lgSUBTLEX','PTAN','Ned1_Diff','Length_Ortho')
checkstats <- rep(0,length(vars2test)) # just a check to use for the conditional while
while (sum(checkstats)!=length(checkstats)) {
# Shuffle and redraw the set and trial indices
dat <- dat[order(sample(1:nrow(dat))),]
dat$setIdx <- as.factor(rep(1:nSets, each = nTrialsInSet))
dat$setTrial <- as.factor(rep(1:nTrialsInSet,nSets))
for (i in 1:length(vars2test)){
# Pairwise comparisons
res.ts <- pairwise.t.test(dat[,vars2test[i]],dat[,'setIdx'], p.adj="none")
# Extract p values
tps <- res.ts$p.value[which(!is.na(res.ts$p.value))]
# Check if any was significant
ifelse(test =length(which(tps<0.05))==0,
yes = checkstats[i]<-1,
no = checkstats[i]<-0)
}
}
# Store the tests once while loop is done
ttests <- list()
for (i in 1:length(vars2test)){
#pairwise comparisons
res.ts <- pairwise.t.test(dat[,vars2test[i]],dat[,'setIdx'], p.adj="none")
# store
ttests[[i]] <- res.ts
}
## Contingency tables and compare proportions
# item length
dat$Length_Ortho <- as.factor(dat$Length_Ortho)
stat <- dlookr::compare_category(setIdx, Length_Ortho,.data = dat) %>%  summary()
# syllable count
stat <- dlookr::compare_category(setIdx, syllableCount,.data = dat) %>%  summary()
# syllable count
stat <- dlookr::compare_category(setIdx, syllableCount,.data = dat) %>%  summary()
if (stat$chisq$p.value < 0.05){
stop('STOP. proportion of trials with a given n of syllables is unbalance between the sets! Rerun or check your requirements')
}
if (stat$chisq$p.value < 0.05){
stop('STOP. proportion of trials with a given n of syllables is unbalance between the sets! Rerun or check your requirements')
}
## Split the data
print(ttests) # print for testing
sets <- split(dat,dat$setIdx)
# Generate sequences for experimental blocks
nNoiseLevels <- 5
nTrialsInSeq <- 60
snrpreffix <-  paste0('SNR',1:nNoiseLevels,'')
subsets <- list()
for (i  in 1:length(sets)) {
currseq <- c(sets[[i]]$Word[1:(nTrialsInSeq/2)],
sets[[i]]$pseudoword[1:(nTrialsInSeq/2)])
#Make n blocks, one for each SNR
blocks <- list()
for (ii in 1:length(currseq)) {
blocks[[ii]] <- paste(snrpreffix,currseq[ii],sep='_')[order(sample(1:5))]
}
Blcks <- as.data.frame(do.call(rbind,blocks))
Blcks <- apply(Blcks,2,sample) # shuffle the rows of each column independently
colnames(Blcks) <- paste0('version',1:dim(Blcks)[2])
subsets[[i]] <- as.data.frame(Blcks)
}
Blcks
1:nrow(Blcks)
cbind(1:nrow(Blcks),Blcks)
install.packages('klippy')
remotes::install_github("rlesur/klippy")
remotes::install_github("rlesur/klippy")
.libs()
Sys.getenv()
R_LIBS()
,libP
.libPaths
.libPaths()
remotes::install_github("rlesur/klipp",dependencies =  TRUE)
install.packages('DT')
library(dt)
library('DT')
library(DT)
knitr::opts_chunk$set(echo = TRUE)
library(gridExtra)
library(dplyr)
library(plotly)
library(ggplot2)
library(nomnoml)
library(kableExtra)
library(DT) # for saving tables
subsets[[1]] %>%
datatable(extensions = 'Buttons',rownames = FALSE,
options = list(dom = 'Blfrtip',
buttons = c('copy', 'csv', 'excel'))
#lengthMenu = list(c(10,25,50,-1),
c(10,25,50,"All"))))
subsets[[1]] %>%
datatable(extensions = 'Buttons',rownames = FALSE,
options = list(dom = 'Blfrtip',
buttons = c('copy', 'csv', 'excel')))
subsets[[1]] %>%
datatable(extensions = 'Buttons',rownames = FALSE,
options = list(dom = 'Blfrtip',
buttons = c('copy', 'csv', 'excel'),
lengthMenu = list(c(10,25,50,-1),
c(10,25,50,"All"))))
subsets[[1]] %>%
datatable(extensions = 'Buttons',rownames = FALSE,
options = list(dom = 'Blfrtip',
buttons = c('copy', 'csv', 'excel'),
show = 100,
lengthMenu = list(c(10,25,50,-1),
c(10,25,50,"All"))))
subsets[[1]] %>%
datatable(extensions = 'Buttons',rownames = FALSE,
options = list(dom = 'Blfrtip',
buttons = c('copy', 'csv', 'excel'),
show = 100,
lengthMenu =  list(c(15, -1), c("15", "All"))))
